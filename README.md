# ğŸ§  ML Model Training API with Flask

# ğŸ“Œ Project Description
 ## Key Features

This is a **Flask-based machine learning model** that triggers model training and predictions on structured CSV data files. It incorporates:

- Utilizes Python libraries such as:
  - ğŸ“¦ `NumPy`, `Pandas` for data handling
  - ğŸ§© `KNNImputer` for imputing missing values
  - ğŸ“ `StandardScaler` for feature scaling
  - ğŸ“Š `KMeans` and `KneeLocator` for data clustering
  - ğŸ§  `RandomForestClassifier` and `LogisticRegression` for modeling
- Includes robust validation and preprocessing pipelines before training.
- **SQLite** as the database.

---

## ğŸ” Workflow Overview

### âœ… 1. File Validation

- Validates incoming files based on **enterprise data naming conventions** using regex.
- Enforces schema compliance: column count, column names, and missing value checks.
- Converts validated input into a **standardized CSV format** for downstream processing.

---

### ğŸ§¹ 2. Data Preprocessing

- Handles missing data using **KNNImputer**.
- Cleans and prunes irrelevant or noisy features.
- Applies:
  - ğŸ”§ **Feature engineering** techniques
  - ğŸ“‰ **Log transformation** to normalize distributions
  - ğŸ“ **Standard scaling** for model compatibility
- Segregates target variables from features to ensure clean modeling.

---

### ğŸ§ª 3. Clustering & Model Selection

- Segments the dataset using **KMeans** clustering.
- Uses **KneeLocator** to auto-select the optimal number of clusters.
- For each cluster:
  - Performs model training with **Random Forest** and **Logistic Regression**
  - Runs **hyperparameter tuning** via grid search to optimize performance
- Selects the **best-performing model per cluster** based on accuracy and business-specific metrics.

---

### ğŸ“¦ 4. Model Saving & Prediction

- Models are saved using **joblib**, organized by cluster for easy retrieval.
- Incoming prediction data:
  - Undergoes the same validation and preprocessing steps
  - Is routed to the appropriate model based on cluster assignment
- Returns predictions along with **confidence scores** or metrics.
- Supports **batch and real-time prediction modes** (with further adaptation).

---

### ğŸ¢ Industry Application Use Case

This project mimics a **production-grade machine learning pipeline** suitable for:

- ğŸ¥ **Healthcare diagnostics**: Assigning patient records to cluster-specific predictive models.
- ğŸ’¼ **Finance**: Risk profiling and fraud detection using behavioral segmentation.
- ğŸ“¦ **Retail**: Product recommendation and demand forecasting tailored to customer segments.
- âš™ï¸ **Manufacturing**: Predictive maintenance using sensor data clusters.

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ app.py #  Main Flask application (API endpoints for training and prediction)
â”œâ”€â”€ training_Model.py #  Contains logic for training models on clustered data
â”œâ”€â”€ training_validation_insert.py #  Validates and inserts training data files
â”œâ”€â”€ Training_Batch_File/ #  Directory to store incoming training data files
â”œâ”€â”€ prediction_validation_insert.py #  Validates and inserts prediction data files
â”œâ”€â”€ Prediction_Batch_File/ #  Directory to store incoming prediction data files
â”œâ”€â”€ predictionModel.py #  Executes the prediction pipeline using saved models
â”œâ”€â”€ templates/ # ğŸ–¼ HTML templates for the web UI (Flask Jinja2 views)
â”œâ”€â”€ requirements.txt #  List of required Python dependencies
â””â”€â”€ README.md #  Project documentation (youâ€™re here!)
```

---

## ğŸš€ Features

âœ… Accepts JSON request with folder path

âœ… Regex-based file validation for training and prediction datasets

ğŸ§¹ Automated data preprocessing with imputation, scaling, and log transformation

ğŸ“Š KMeans clustering to segment data for model-specific training

ğŸ§  Model training with RandomForest and LogisticRegression per cluster

ğŸ§ª Hyperparameter tuning for optimal model performance

ğŸ’¾ Model saving and reuse for production-ready predictions

ğŸ“ˆ Prediction workflow mirrors training for consistency and accuracy

ğŸ–¥ï¸ Web UI support via HTML templates for user interaction

---

## ğŸ“¡ API Endpoint

### `POST /train`

**Request Body:**
```json
{
  "folderPath": "Training_Batch_Files"
}
```

**Response:**
- âœ… Success: `"Training completed successfully."`
- âŒ Error: `"Error occurred! <Exception Details>"`

---

## ğŸ”§ How to Run

### 1. Clone the Repository
```bash
git clone https://github.com/your-username/ml-training-api.git
cd ml-training-api
```

### 2. Create & Activate Virtual Environment
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Run the Flask Server
```bash
python app.py
```

Server will run on: `http://127.0.0.1:5001`

---

## ğŸ“¬ Example Request Using cURL

```bash
curl --location 'http://127.0.0.1:5001/train' \
--header 'Content-Type: application/json' \
--data '{
  "folderPath": "Training_Batch_Files"
}'
```

---

## âš ï¸ Common Issues

- **Mac Compatibility**: Use `n_jobs=1` for parallel training to avoid multiprocessing issues on macOS.
- **Path Errors**: Always use absolute paths or make sure your working directory is correct.
- **KeyError**: Ensure the JSON body has `"folderPath"` key.

---

## ğŸ¤– Model Training Notes

- Uses `GridSearchCV` for hyperparameter tuning
- Trains models like Linear Regression
- Stores best model based on cross-validation score
- Future plan: add model persistence with `joblib` and prediction endpoint

---

## ğŸ“¦ Requirements

- Flask
- pandas
- scikit-learn
- numpy
- flask-cors

You can install them with:

```bash
pip install -r requirements.txt
```

---

## ğŸ™Œ Contributions

Pull requests are welcome! Feel free to open issues or suggest improvements.

---

## ğŸ“„ License

This project is open source and available under the [MIT License](LICENSE).

---
